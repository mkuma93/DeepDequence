{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04635246",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Add the package to path if needed\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from deepsequence.deepsequence_pwl import DeepSequencePWL\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382e3ef",
   "metadata": {},
   "source": [
    "## 2. Generate Sample Data\n",
    "\n",
    "Let's create synthetic time series data with:\n",
    "- Multiple SKUs (products)\n",
    "- Trend, seasonality, and noise\n",
    "- High zero rate (sparse/intermittent demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03943217",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "n_samples = 10000\n",
    "n_skus = 25\n",
    "n_features = 4\n",
    "zero_rate = 0.90  # 90% zeros (highly sparse)\n",
    "\n",
    "# Generate features\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Generate SKU IDs\n",
    "sku_ids = np.random.randint(0, n_skus, n_samples)\n",
    "\n",
    "# Generate target with trend and seasonality\n",
    "time_index = np.arange(n_samples)\n",
    "trend = 0.01 * time_index / 100\n",
    "seasonality = 5 * np.sin(2 * np.pi * time_index / 365)\n",
    "noise = np.random.randn(n_samples) * 2\n",
    "\n",
    "y_magnitude = np.maximum(0, 10 + trend + seasonality + X.sum(axis=1) + noise)\n",
    "\n",
    "# Apply sparsity (intermittent demand)\n",
    "zero_mask = np.random.rand(n_samples) < zero_rate\n",
    "y = y_magnitude.copy()\n",
    "y[zero_mask] = 0\n",
    "\n",
    "print(f\"Dataset created:\")\n",
    "print(f\"  Samples: {n_samples:,}\")\n",
    "print(f\"  SKUs: {n_skus}\")\n",
    "print(f\"  Features: {n_features}\")\n",
    "print(f\"  Zero rate: {(y == 0).mean():.1%}\")\n",
    "print(f\"  Non-zero mean: {y[y > 0].mean():.2f}\")\n",
    "print(f\"  Non-zero std: {y[y > 0].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0987741",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ebe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 70% train, 15% validation, 15% test\n",
    "X_temp, X_test, y_temp, y_test, sku_temp, sku_test = train_test_split(\n",
    "    X, y, sku_ids, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val, sku_train, sku_val = train_test_split(\n",
    "    X_temp, y_temp, sku_temp, test_size=0.176, random_state=42  # 0.176 * 0.85 ≈ 0.15\n",
    ")\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Train: {len(X_train):,} samples ({len(X_train)/n_samples:.1%})\")\n",
    "print(f\"  Val:   {len(X_val):,} samples ({len(X_val)/n_samples:.1%})\")\n",
    "print(f\"  Test:  {len(X_test):,} samples ({len(X_test)/n_samples:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017793c",
   "metadata": {},
   "source": [
    "## 4. Model 1: Intermittent Demand (Two-Stage Prediction)\n",
    "\n",
    "This mode is ideal for sparse/intermittent demand with high zero rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eed12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with intermittent handling enabled\n",
    "model_intermittent = DeepSequencePWL(\n",
    "    num_skus=n_skus,\n",
    "    n_features=n_features,\n",
    "    enable_intermittent_handling=True,  # Two-stage prediction\n",
    "    id_embedding_dim=8,\n",
    "    component_hidden_units=32,\n",
    "    component_dropout=0.2,\n",
    "    zero_prob_hidden_units=64,\n",
    "    zero_prob_hidden_layers=2,\n",
    "    zero_prob_dropout=0.2,\n",
    "    activation='mish'\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "main_model, trend_model, seasonal_model, holiday_model, regressor_model = model_intermittent.build_model()\n",
    "\n",
    "print(f\"\\n✓ Intermittent model built\")\n",
    "print(f\"  Total parameters: {main_model.count_params():,}\")\n",
    "print(f\"  Outputs: {list(main_model.output.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train\n",
    "main_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'final_forecast': 'mae'},\n",
    "    metrics={'final_forecast': ['mae']}\n",
    ")\n",
    "\n",
    "print(\"Training intermittent model...\\n\")\n",
    "history = main_model.fit(\n",
    "    [X_train, sku_train],\n",
    "    {'final_forecast': y_train},\n",
    "    validation_data=([X_val, sku_val], {'final_forecast': y_val}),\n",
    "    epochs=3,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "predictions_intermittent = main_model.predict([X_test, sku_test], verbose=0)\n",
    "\n",
    "y_pred = predictions_intermittent['final_forecast'].flatten()\n",
    "zero_prob = predictions_intermittent['zero_probability'].flatten()\n",
    "\n",
    "test_mae = np.abs(y_test - y_pred).mean()\n",
    "\n",
    "print(f\"\\nIntermittent Model Performance:\")\n",
    "print(f\"  Test MAE: {test_mae:.4f}\")\n",
    "print(f\"  Zero probability range: [{zero_prob.min():.3f}, {zero_prob.max():.3f}]\")\n",
    "print(f\"  Mean zero probability: {zero_prob.mean():.3f}\")\n",
    "print(f\"  Actual zero rate: {(y_test == 0).mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb47553",
   "metadata": {},
   "source": [
    "## 5. Model 2: Continuous Demand (Direct Forecast)\n",
    "\n",
    "This mode is ideal for regular continuous demand forecasting with fewer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cfbabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with intermittent handling disabled\n",
    "model_continuous = DeepSequencePWL(\n",
    "    num_skus=n_skus,\n",
    "    n_features=n_features,\n",
    "    enable_intermittent_handling=False,  # Direct forecast only\n",
    "    id_embedding_dim=8,\n",
    "    component_hidden_units=32,\n",
    "    component_dropout=0.2,\n",
    "    activation='mish'\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "main_model2, _, _, _, _ = model_continuous.build_model()\n",
    "\n",
    "print(f\"\\n✓ Continuous model built\")\n",
    "print(f\"  Total parameters: {main_model2.count_params():,}\")\n",
    "print(f\"  Parameter savings: {(1 - main_model2.count_params()/main_model.count_params())*100:.1f}%\")\n",
    "print(f\"  Outputs: {list(main_model2.output.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train\n",
    "main_model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'final_forecast': 'mae'},\n",
    "    metrics={'final_forecast': ['mae']}\n",
    ")\n",
    "\n",
    "print(\"Training continuous model...\\n\")\n",
    "history2 = main_model2.fit(\n",
    "    [X_train, sku_train],\n",
    "    {'final_forecast': y_train},\n",
    "    validation_data=([X_val, sku_val], {'final_forecast': y_val}),\n",
    "    epochs=3,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "predictions_continuous = main_model2.predict([X_test, sku_test], verbose=0)\n",
    "\n",
    "y_pred2 = predictions_continuous['final_forecast'].flatten()\n",
    "\n",
    "test_mae2 = np.abs(y_test - y_pred2).mean()\n",
    "\n",
    "print(f\"\\nContinuous Model Performance:\")\n",
    "print(f\"  Test MAE: {test_mae2:.4f}\")\n",
    "print(f\"  Note: Higher MAE expected for sparse data without intermittent handling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0111babf",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783220db",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Intermittent (Two-Stage)', 'Continuous (Direct)'],\n",
    "    'Parameters': [main_model.count_params(), main_model2.count_params()],\n",
    "    'Test MAE': [test_mae, test_mae2],\n",
    "    'Best For': ['Sparse/intermittent demand (high zero rate)', 'Regular continuous demand']\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n✓ For this dataset (zero rate: {(y_test == 0).mean():.1%}):\")\n",
    "print(f\"  Intermittent model is {test_mae2/test_mae:.1f}x better\")\n",
    "print(f\"  Using {main_model.count_params() - main_model2.count_params():,} more parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b161d47",
   "metadata": {},
   "source": [
    "## 7. Component Analysis (Intermittent Model)\n",
    "\n",
    "Let's examine the individual component contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample for analysis\n",
    "sample_idx = 0\n",
    "sample_X = X_test[sample_idx:sample_idx+1]\n",
    "sample_sku = sku_test[sample_idx:sample_idx+1]\n",
    "sample_y = y_test[sample_idx]\n",
    "\n",
    "# Get predictions from individual components\n",
    "trend_pred = trend_model.predict([sample_X, sample_sku], verbose=0)[0, 0]\n",
    "seasonal_pred = seasonal_model.predict([sample_X, sample_sku], verbose=0)[0, 0]\n",
    "holiday_pred = holiday_model.predict([sample_X, sample_sku], verbose=0)[0, 0]\n",
    "regressor_pred = regressor_model.predict([sample_X, sample_sku], verbose=0)[0, 0]\n",
    "\n",
    "# Get main model predictions\n",
    "main_pred = main_model.predict([sample_X, sample_sku], verbose=0)\n",
    "base_forecast = main_pred['base_forecast'][0, 0]\n",
    "final_forecast = main_pred['final_forecast'][0, 0]\n",
    "zero_prob = main_pred['zero_probability'][0, 0]\n",
    "\n",
    "print(f\"\\nComponent Analysis for Sample {sample_idx}:\")\n",
    "print(f\"  Trend:       {trend_pred:8.4f}\")\n",
    "print(f\"  Seasonal:    {seasonal_pred:8.4f}\")\n",
    "print(f\"  Holiday:     {holiday_pred:8.4f}\")\n",
    "print(f\"  Regressor:   {regressor_pred:8.4f}\")\n",
    "print(f\"  \" + \"-\" * 30)\n",
    "print(f\"  Base forecast:  {base_forecast:8.4f}\")\n",
    "print(f\"  Zero prob:      {zero_prob:8.4f}\")\n",
    "print(f\"  Final forecast: {final_forecast:8.4f}\")\n",
    "print(f\"  Actual value:   {sample_y:8.4f}\")\n",
    "print(f\"  Error:          {abs(final_forecast - sample_y):8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b959eb",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Intermittent Mode** (`enable_intermittent_handling=True`):\n",
    "   - Includes zero probability network\n",
    "   - Best for sparse/intermittent demand (high zero rate)\n",
    "   - More parameters but better accuracy for sparse data\n",
    "\n",
    "2. **Continuous Mode** (`enable_intermittent_handling=False`):\n",
    "   - Direct forecast without zero probability overhead\n",
    "   - Best for regular continuous demand\n",
    "   - 86% fewer parameters, more efficient\n",
    "\n",
    "3. **Components**:\n",
    "   - Trend: Captures long-term patterns\n",
    "   - Seasonal: Captures periodic patterns\n",
    "   - Holiday: Captures special events (PWL + Lattice)\n",
    "   - Regressor: Captures feature relationships\n",
    "   - All combined additively for interpretability\n",
    "\n",
    "### When to Use:\n",
    "\n",
    "- **High zero rate (>70%)**: Use intermittent mode\n",
    "- **Low zero rate (<30%)**: Use continuous mode\n",
    "- **Mixed scenarios**: Test both and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d3c3b",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Try with your own data\n",
    "2. Tune hyperparameters (hidden units, dropout, layers)\n",
    "3. Experiment with different activations ('mish', 'relu', 'elu')\n",
    "4. Train for more epochs with early stopping\n",
    "5. Analyze component contributions for insights\n",
    "\n",
    "See `deepsequence/deepsequence_pwl/README.md` for detailed documentation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
