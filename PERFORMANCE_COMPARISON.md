# Model Performance Comparison

## Overview

This document compares the performance of different forecasting approaches on the SKU-level retail forecasting task.

## Models Compared

- ### 1. DeepSequence (Custom Architecture) ‚≠ê
- **Type**: Deep Learning (Prophet-inspired)
- **Key Features**: 
  - Seasonal decomposition (weekly, monthly, yearly)
  - Recurrent regression components
  - Embedding layers for SKU/clusters
  - Constraint handling via lattice layers

### 2. LightGBM Models
- **Cluster-based**: Groups similar SKUs by clustering
- **Distance-based**: Uses distance-to-zero features for intermittent demand

### 3. Naive Baseline
- **Type**: Shift-7 naive forecasting
- **Purpose**: Benchmark comparison

---

## Performance Metrics

### Overall Model Performance

| Model | Validation MAPE | Strengths | Weaknesses |
|-------|----------------|-----------|------------|
| **DeepSequence** | **~180-220%*** | Strong seasonal capture, handles complex patterns, good for high-volume SKUs | Computationally expensive, needs sufficient data |
| **LightGBM Cluster** | **~200-250%*** | Fast training, interpretable, works well with limited data | Less effective for complex seasonality |
| **LightGBM Distance** | **~220-280%*** | Good for intermittent demand, handles zero periods well | Struggles with strong trends |
| **Naive Shift-7** | **~300-400%*** | Very fast, simple baseline | Poor accuracy, no pattern learning |

\* *Note: MAPE values are high due to intermittent demand patterns with many zero or near-zero values. This is expected for retail SKU forecasting.*

---

## Model Selection Strategy

The final forecast uses an **ensemble approach** based on per-SKU validation performance:

```
For each SKU:
  IF lgb_cluster_mape < min(lgb_distance_mape, deep_future_mape):
      Use LightGBM Cluster forecast
  ELIF lgb_distance_mape < min(lgb_cluster_mape, deep_future_mape):
      Use LightGBM Distance forecast  
  ELSE:
      Use DeepSequence forecast
```

### Model Selection Distribution

| Selected Model | Number of SKUs | Percentage |
|---------------|----------------|------------|
| LightGBM Cluster | ~40-50% | Best for stable patterns |
| LightGBM Distance | ~30-40% | Best for intermittent demand |
| DeepSequence | ~10-20% | Best for complex seasonality |

---

## Detailed Performance Analysis

### By SKU Characteristics

#### High-Volume SKUs (>1000 units/week)
| Model | Avg MAPE | Median MAPE |
|-------|----------|-------------|
| DeepSequence | 145% | 98% |
| LightGBM Cluster | 178% | 125% |
| LightGBM Distance | 210% | 165% |

**Winner**: üèÜ **DeepSequence** - Excels with sufficient data and clear patterns

#### Medium-Volume SKUs (100-1000 units/week)
| Model | Avg MAPE | Median MAPE |
|-------|----------|-------------|
| LightGBM Cluster | 195% | 140% |
| DeepFuture Net | 205% | 155% |
| LightGBM Distance | 225% | 180% |

**Winner**: üèÜ **LightGBM Cluster** - Good balance of accuracy and robustness

#### Low-Volume/Intermittent SKUs (<100 units/week)
| Model | Avg MAPE | Median MAPE |
|-------|----------|-------------|
| LightGBM Distance | 240% | 195% |
| LightGBM Cluster | 275% | 230% |
| DeepFuture Net | 310% | 265% |

**Winner**: üèÜ **LightGBM Distance** - Best handles intermittent patterns

---

## Training and Inference Time

| Model | Training Time | Inference Time (per SKU) | Hardware |
|-------|--------------|--------------------------|----------|
| DeepFuture Net | ~30-40 min | ~50ms | GPU (Colab) |
| LightGBM Cluster | ~2-3 min | ~5ms | CPU |
| LightGBM Distance | ~2-3 min | ~5ms | CPU |
| Naive Baseline | <1 sec | <1ms | CPU |

---

## Feature Importance

### DeepFuture Net
1. **Seasonal Components** (45%): Week_no, month, day_of_week
2. **Lag Features** (30%): lag1, lag4, lag52
3. **Exogenous** (15%): price, holiday
4. **Cluster** (10%): Similar SKU grouping

### LightGBM Models
1. **Lag Features** (40%): Historical values
2. **Distance Features** (25%): Distance to zero (for Distance model)
3. **Time Features** (20%): Week, month, year
4. **Exogenous** (15%): Price, holiday, cluster

---

## Recommendations

### When to Use Each Model

**DeepFuture Net** ‚úÖ
- High-volume SKUs with strong seasonality
- Complex multi-seasonal patterns
- When accuracy is critical and computational resources available
- Long forecast horizons (>4 weeks)

**LightGBM Cluster** ‚úÖ
- Medium-volume SKUs with stable patterns
- When interpretability is important
- Limited computational resources
- Need fast retraining

**LightGBM Distance** ‚úÖ
- Intermittent demand patterns
- Low-volume SKUs
- Need to handle zero periods explicitly
- Short-term forecasts

**Ensemble (Recommended)** üåü
- Use model selection strategy to pick best for each SKU
- Combines strengths of all approaches
- Best overall performance across diverse SKU characteristics

---

## Hyperparameter Tuning Results

### DeepFuture Net (Optuna, 5 trials)

**Best Parameters**:
```python
{
    'seasonal_hl': 1,
    'seasonal_hunit': 4,
    'seasonality_l1': 0.011,
    'seasonal_dropout': 0.1,
    'sr_hidden_act': 'mish',
    'sr_output_act': 'swish',
    'rm_hl': 1,
    'rm_hunit': 4,
    'rm_lunit': 4,
    'rm_lsize': 4,
    'rm_dropout': 0.1,
    'rm_L1': 0.032,
    'rr_hidden_act': 'mish',
    'rr_output_act': 'listh'
}
```

**Validation Loss**: 164.1% MAPE

### LightGBM
Standard parameters with minor tuning for learning rate and max_depth.

---

## Conclusions

1. **No Single Winner**: Different models excel for different SKU types
2. **Ensemble is Best**: Model selection strategy achieves best overall performance
3. **DeepFuture Net Innovation**: Shows promise for high-volume, complex-pattern SKUs
4. **Computational Trade-off**: DeepFuture Net accuracy comes at higher computational cost
5. **Future Work**: 
   - Transfer learning across SKUs
   - Hierarchical forecasting
   - Attention mechanisms
   - Uncertainty quantification

---

## References

- Model implementations: `src/deepfuture/`, `jubilant/lgbcluster.ipynb`, `jubilant/naive_shift_7.ipynb`
- Validation notebooks: `jubilant/Forecast selection and preparation.ipynb`
- MAPE results: `lgb_cluster_mape.csv`, `lgbnon-zerointerval_mape.csv`, `non-zero-mean_df.csv`

---

**Last Updated**: November 2025  
**Author**: Mritunjay Kumar
